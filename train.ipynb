{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b24273c7",
   "metadata": {},
   "source": [
    "Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "727cc82e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain\n",
      "  Downloading langchain-0.3.27-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting langchain-community\n",
      "  Downloading langchain_community-0.3.27-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting chromadb\n",
      "  Downloading chromadb-1.0.17-cp39-abi3-macosx_11_0_arm64.whl.metadata (7.3 kB)\n",
      "Collecting sentence-transformers\n",
      "  Downloading sentence_transformers-5.1.0-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.7.1-cp310-cp310-macosx_12_0_arm64.whl.metadata (11 kB)\n",
      "Collecting pypdf\n",
      "  Downloading pypdf-6.0.0-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting python-dotenv\n",
      "  Using cached python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting openai\n",
      "  Downloading openai-1.99.9-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting tiktoken\n",
      "  Downloading tiktoken-0.11.0-cp310-cp310-macosx_11_0_arm64.whl.metadata (6.7 kB)\n",
      "Collecting fastapi\n",
      "  Using cached fastapi-0.116.1-py3-none-any.whl.metadata (28 kB)\n",
      "Collecting uvicorn\n",
      "  Using cached uvicorn-0.35.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting pydantic\n",
      "  Using cached pydantic-2.11.7-py3-none-any.whl.metadata (67 kB)\n",
      "Collecting supabase\n",
      "  Downloading supabase-2.18.1-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting langchain-core<1.0.0,>=0.3.72 (from langchain)\n",
      "  Downloading langchain_core-0.3.74-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting langchain-text-splitters<1.0.0,>=0.3.9 (from langchain)\n",
      "  Downloading langchain_text_splitters-0.3.9-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting langsmith>=0.1.17 (from langchain)\n",
      "  Downloading langsmith-0.4.14-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain)\n",
      "  Downloading sqlalchemy-2.0.43-cp310-cp310-macosx_11_0_arm64.whl.metadata (9.6 kB)\n",
      "Collecting requests<3,>=2 (from langchain)\n",
      "  Using cached requests-2.32.4-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting PyYAML>=5.3 (from langchain)\n",
      "  Using cached PyYAML-6.0.2-cp310-cp310-macosx_11_0_arm64.whl.metadata (2.1 kB)\n",
      "Collecting async-timeout<5.0.0,>=4.0.0 (from langchain)\n",
      "  Downloading async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.33.2 (from pydantic)\n",
      "  Using cached pydantic_core-2.33.2-cp310-cp310-macosx_11_0_arm64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in /Users/saniyaacharya/Library/Python/3.10/lib/python/site-packages (from pydantic) (4.14.1)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic)\n",
      "  Using cached typing_inspection-0.4.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting tenacity!=8.4.0,<10.0.0,>=8.1.0 (from langchain-core<1.0.0,>=0.3.72->langchain)\n",
      "  Using cached tenacity-9.1.2-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<1.0.0,>=0.3.72->langchain)\n",
      "  Using cached jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: packaging>=23.2 in /Users/saniyaacharya/Library/Python/3.10/lib/python/site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (25.0)\n",
      "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain)\n",
      "  Using cached jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting charset_normalizer<4,>=2 (from requests<3,>=2->langchain)\n",
      "  Downloading charset_normalizer-3.4.3-cp310-cp310-macosx_10_9_universal2.whl.metadata (36 kB)\n",
      "Collecting idna<4,>=2.5 (from requests<3,>=2->langchain)\n",
      "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests<3,>=2->langchain)\n",
      "  Using cached urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests<3,>=2->langchain)\n",
      "  Using cached certifi-2025.8.3-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain-community)\n",
      "  Downloading aiohttp-3.12.15-cp310-cp310-macosx_11_0_arm64.whl.metadata (7.7 kB)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
      "  Downloading pydantic_settings-2.10.1-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community)\n",
      "  Downloading httpx_sse-0.4.1-py3-none-any.whl.metadata (9.4 kB)\n",
      "Collecting numpy>=1.26.2 (from langchain-community)\n",
      "  Using cached numpy-2.2.6-cp310-cp310-macosx_14_0_arm64.whl.metadata (62 kB)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.4.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Using cached aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Using cached attrs-25.3.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Using cached frozenlist-1.7.0-cp310-cp310-macosx_11_0_arm64.whl.metadata (18 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading multidict-6.6.4-cp310-cp310-macosx_11_0_arm64.whl.metadata (5.3 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Using cached propcache-0.3.2-cp310-cp310-macosx_11_0_arm64.whl.metadata (12 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Using cached yarl-1.20.1-cp310-cp310-macosx_11_0_arm64.whl.metadata (73 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting build>=1.0.3 (from chromadb)\n",
      "  Downloading build-1.3.0-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting pybase64>=1.4.1 (from chromadb)\n",
      "  Downloading pybase64-1.4.2-cp310-cp310-macosx_11_0_arm64.whl.metadata (8.7 kB)\n",
      "Collecting posthog<6.0.0,>=2.4.0 (from chromadb)\n",
      "  Using cached posthog-5.4.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting onnxruntime>=1.14.1 (from chromadb)\n",
      "  Downloading onnxruntime-1.22.1-cp310-cp310-macosx_13_0_universal2.whl.metadata (4.6 kB)\n",
      "Collecting opentelemetry-api>=1.2.0 (from chromadb)\n",
      "  Downloading opentelemetry_api-1.36.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.36.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting opentelemetry-sdk>=1.2.0 (from chromadb)\n",
      "  Downloading opentelemetry_sdk-1.36.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting tokenizers>=0.13.2 (from chromadb)\n",
      "  Using cached tokenizers-0.21.4-cp39-abi3-macosx_11_0_arm64.whl.metadata (6.7 kB)\n",
      "Collecting pypika>=0.48.9 (from chromadb)\n",
      "  Using cached PyPika-0.48.9.tar.gz (67 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting tqdm>=4.65.0 (from chromadb)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting overrides>=7.3.1 (from chromadb)\n",
      "  Using cached overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting importlib-resources (from chromadb)\n",
      "  Using cached importlib_resources-6.5.2-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting grpcio>=1.58.0 (from chromadb)\n",
      "  Downloading grpcio-1.74.0-cp310-cp310-macosx_11_0_universal2.whl.metadata (3.8 kB)\n",
      "Collecting bcrypt>=4.0.1 (from chromadb)\n",
      "  Using cached bcrypt-4.3.0-cp39-abi3-macosx_10_12_universal2.whl.metadata (10 kB)\n",
      "Collecting typer>=0.9.0 (from chromadb)\n",
      "  Using cached typer-0.16.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting kubernetes>=28.1.0 (from chromadb)\n",
      "  Using cached kubernetes-33.1.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting mmh3>=4.0.1 (from chromadb)\n",
      "  Downloading mmh3-5.2.0-cp310-cp310-macosx_11_0_arm64.whl.metadata (14 kB)\n",
      "Collecting orjson>=3.9.12 (from chromadb)\n",
      "  Downloading orjson-3.11.2-cp310-cp310-macosx_10_15_x86_64.macosx_11_0_arm64.macosx_10_15_universal2.whl.metadata (1.2 kB)\n",
      "Collecting httpx>=0.27.0 (from chromadb)\n",
      "  Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting rich>=10.11.0 (from chromadb)\n",
      "  Downloading rich-14.1.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting jsonschema>=4.19.0 (from chromadb)\n",
      "  Using cached jsonschema-4.25.0-py3-none-any.whl.metadata (7.7 kB)\n",
      "Requirement already satisfied: six>=1.5 in /Users/saniyaacharya/Library/Python/3.10/lib/python/site-packages (from posthog<6.0.0,>=2.4.0->chromadb) (1.17.0)\n",
      "Requirement already satisfied: python-dateutil>=2.2 in /Users/saniyaacharya/Library/Python/3.10/lib/python/site-packages (from posthog<6.0.0,>=2.4.0->chromadb) (2.9.0.post0)\n",
      "Collecting backoff>=1.10.0 (from posthog<6.0.0,>=2.4.0->chromadb)\n",
      "  Using cached backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting distro>=1.5.0 (from posthog<6.0.0,>=2.4.0->chromadb)\n",
      "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting transformers<5.0.0,>=4.41.0 (from sentence-transformers)\n",
      "  Downloading transformers-4.55.2-py3-none-any.whl.metadata (41 kB)\n",
      "Collecting torch>=1.11.0 (from sentence-transformers)\n",
      "  Downloading torch-2.8.0-cp310-none-macosx_11_0_arm64.whl.metadata (30 kB)\n",
      "Collecting scipy (from sentence-transformers)\n",
      "  Using cached scipy-1.15.3-cp310-cp310-macosx_14_0_arm64.whl.metadata (61 kB)\n",
      "Collecting huggingface-hub>=0.20.0 (from sentence-transformers)\n",
      "  Using cached huggingface_hub-0.34.4-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting Pillow (from sentence-transformers)\n",
      "  Using cached pillow-11.3.0-cp310-cp310-macosx_11_0_arm64.whl.metadata (9.0 kB)\n",
      "Collecting filelock (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Downloading filelock-3.19.1-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting regex!=2019.12.17 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Downloading regex-2025.7.34-cp310-cp310-macosx_11_0_arm64.whl.metadata (40 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Using cached safetensors-0.6.2-cp38-abi3-macosx_11_0_arm64.whl.metadata (4.1 kB)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub>=0.20.0->sentence-transformers)\n",
      "  Using cached fsspec-2025.7.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting hf-xet<2.0.0,>=1.1.3 (from huggingface-hub>=0.20.0->sentence-transformers)\n",
      "  Using cached hf_xet-1.1.7-cp37-abi3-macosx_11_0_arm64.whl.metadata (703 bytes)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Using cached joblib-1.5.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Using cached threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting anyio<5,>=3.5.0 (from openai)\n",
      "  Downloading anyio-4.10.0-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting jiter<1,>=0.4.0 (from openai)\n",
      "  Downloading jiter-0.10.0-cp310-cp310-macosx_11_0_arm64.whl.metadata (5.2 kB)\n",
      "Collecting sniffio (from openai)\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/saniyaacharya/Library/Python/3.10/lib/python/site-packages (from anyio<5,>=3.5.0->openai) (1.3.0)\n",
      "Collecting httpcore==1.* (from httpx>=0.27.0->chromadb)\n",
      "  Using cached httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting h11>=0.16 (from httpcore==1.*->httpx>=0.27.0->chromadb)\n",
      "  Using cached h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting starlette<0.48.0,>=0.40.0 (from fastapi)\n",
      "  Downloading starlette-0.47.2-py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting click>=7.0 (from uvicorn)\n",
      "  Using cached click-8.2.1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting postgrest==1.1.1 (from supabase)\n",
      "  Downloading postgrest-1.1.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting realtime==2.7.0 (from supabase)\n",
      "  Downloading realtime-2.7.0-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting supabase-auth==2.12.3 (from supabase)\n",
      "  Downloading supabase_auth-2.12.3-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting storage3==0.12.1 (from supabase)\n",
      "  Downloading storage3-0.12.1-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting supabase-functions==0.10.1 (from supabase)\n",
      "  Downloading supabase_functions-0.10.1-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting deprecation<3.0.0,>=2.1.0 (from postgrest==1.1.1->supabase)\n",
      "  Downloading deprecation-2.1.0-py2.py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting strenum<0.5.0,>=0.4.9 (from postgrest==1.1.1->supabase)\n",
      "  Downloading StrEnum-0.4.15-py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting websockets<16,>=11 (from realtime==2.7.0->supabase)\n",
      "  Downloading websockets-15.0.1-cp310-cp310-macosx_11_0_arm64.whl.metadata (6.8 kB)\n",
      "Collecting pyjwt<3.0.0,>=2.10.1 (from supabase-auth==2.12.3->supabase)\n",
      "  Downloading PyJWT-2.10.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting h2<5,>=3 (from httpx[http2]<0.29,>=0.26->postgrest==1.1.1->supabase)\n",
      "  Downloading h2-4.2.0-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting hyperframe<7,>=6.1 (from h2<5,>=3->httpx[http2]<0.29,>=0.26->postgrest==1.1.1->supabase)\n",
      "  Downloading hyperframe-6.1.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting hpack<5,>=4.1 (from h2<5,>=3->httpx[http2]<0.29,>=0.26->postgrest==1.1.1->supabase)\n",
      "  Downloading hpack-4.1.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting pyproject_hooks (from build>=1.0.3->chromadb)\n",
      "  Using cached pyproject_hooks-1.2.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting tomli>=1.1.0 (from build>=1.0.3->chromadb)\n",
      "  Downloading tomli-2.2.1-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema>=4.19.0->chromadb)\n",
      "  Using cached jsonschema_specifications-2025.4.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting referencing>=0.28.4 (from jsonschema>=4.19.0->chromadb)\n",
      "  Using cached referencing-0.36.2-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting rpds-py>=0.7.1 (from jsonschema>=4.19.0->chromadb)\n",
      "  Downloading rpds_py-0.27.0-cp310-cp310-macosx_11_0_arm64.whl.metadata (4.2 kB)\n",
      "Collecting google-auth>=1.0.1 (from kubernetes>=28.1.0->chromadb)\n",
      "  Using cached google_auth-2.40.3-py2.py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 (from kubernetes>=28.1.0->chromadb)\n",
      "  Using cached websocket_client-1.8.0-py3-none-any.whl.metadata (8.0 kB)\n",
      "Collecting requests-oauthlib (from kubernetes>=28.1.0->chromadb)\n",
      "  Using cached requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\n",
      "Collecting oauthlib>=3.2.2 (from kubernetes>=28.1.0->chromadb)\n",
      "  Using cached oauthlib-3.3.1-py3-none-any.whl.metadata (7.9 kB)\n",
      "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb)\n",
      "  Using cached durationpy-0.10-py3-none-any.whl.metadata (340 bytes)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb)\n",
      "  Using cached cachetools-5.5.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb)\n",
      "  Using cached pyasn1_modules-0.4.2-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb)\n",
      "  Using cached rsa-4.9.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting pyasn1>=0.1.3 (from rsa<5,>=3.1.4->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb)\n",
      "  Using cached pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting requests-toolbelt>=1.0.0 (from langsmith>=0.1.17->langchain)\n",
      "  Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting zstandard>=0.23.0 (from langsmith>=0.1.17->langchain)\n",
      "  Downloading zstandard-0.24.0-cp310-cp310-macosx_11_0_arm64.whl.metadata (3.1 kB)\n",
      "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n",
      "  Using cached coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Collecting flatbuffers (from onnxruntime>=1.14.1->chromadb)\n",
      "  Using cached flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Collecting protobuf (from onnxruntime>=1.14.1->chromadb)\n",
      "  Downloading protobuf-6.32.0-cp39-abi3-macosx_10_9_universal2.whl.metadata (593 bytes)\n",
      "Collecting sympy (from onnxruntime>=1.14.1->chromadb)\n",
      "  Using cached sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting importlib-metadata<8.8.0,>=6.0 (from opentelemetry-api>=1.2.0->chromadb)\n",
      "  Using cached importlib_metadata-8.7.0-py3-none-any.whl.metadata (4.8 kB)\n",
      "Collecting zipp>=3.20 (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb)\n",
      "  Using cached zipp-3.23.0-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting googleapis-common-protos~=1.57 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Using cached googleapis_common_protos-1.70.0-py3-none-any.whl.metadata (9.3 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.36.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_common-1.36.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting opentelemetry-proto==1.36.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Downloading opentelemetry_proto-1.36.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.57b0 (from opentelemetry-sdk>=1.2.0->chromadb)\n",
      "  Downloading opentelemetry_semantic_conventions-0.57b0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich>=10.11.0->chromadb)\n",
      "  Downloading markdown_it_py-4.0.0-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/saniyaacharya/Library/Python/3.10/lib/python/site-packages (from rich>=10.11.0->chromadb) (2.19.2)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb)\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting networkx (from torch>=1.11.0->sentence-transformers)\n",
      "  Using cached networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting jinja2 (from torch>=1.11.0->sentence-transformers)\n",
      "  Using cached jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy->onnxruntime>=1.14.1->chromadb)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting shellingham>=1.3.0 (from typer>=0.9.0->chromadb)\n",
      "  Using cached shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading httptools-0.6.4-cp310-cp310-macosx_11_0_arm64.whl.metadata (3.6 kB)\n",
      "Collecting uvloop>=0.15.1 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading uvloop-0.21.0-cp310-cp310-macosx_10_9_universal2.whl.metadata (4.9 kB)\n",
      "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading watchfiles-1.1.0-cp310-cp310-macosx_11_0_arm64.whl.metadata (4.9 kB)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
      "  Using cached humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch>=1.11.0->sentence-transformers)\n",
      "  Using cached MarkupSafe-3.0.2-cp310-cp310-macosx_11_0_arm64.whl.metadata (4.0 kB)\n",
      "Downloading langchain-0.3.27-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached pydantic-2.11.7-py3-none-any.whl (444 kB)\n",
      "Using cached pydantic_core-2.33.2-cp310-cp310-macosx_11_0_arm64.whl (1.9 MB)\n",
      "Downloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Downloading langchain_core-0.3.74-py3-none-any.whl (443 kB)\n",
      "Using cached jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading langchain_text_splitters-0.3.9-py3-none-any.whl (33 kB)\n",
      "Using cached requests-2.32.4-py3-none-any.whl (64 kB)\n",
      "Downloading charset_normalizer-3.4.3-cp310-cp310-macosx_10_9_universal2.whl (207 kB)\n",
      "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Downloading sqlalchemy-2.0.43-cp310-cp310-macosx_11_0_arm64.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m43.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached tenacity-9.1.2-py3-none-any.whl (28 kB)\n",
      "Using cached urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
      "Downloading langchain_community-0.3.27-py3-none-any.whl (2.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m45.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading aiohttp-3.12.15-cp310-cp310-macosx_11_0_arm64.whl (468 kB)\n",
      "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Downloading httpx_sse-0.4.1-py3-none-any.whl (8.1 kB)\n",
      "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
      "Downloading multidict-6.6.4-cp310-cp310-macosx_11_0_arm64.whl (44 kB)\n",
      "Downloading pydantic_settings-2.10.1-py3-none-any.whl (45 kB)\n",
      "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Using cached yarl-1.20.1-cp310-cp310-macosx_11_0_arm64.whl (89 kB)\n",
      "Downloading chromadb-1.0.17-cp39-abi3-macosx_11_0_arm64.whl (18.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m47.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached posthog-5.4.0-py3-none-any.whl (105 kB)\n",
      "Downloading sentence_transformers-5.1.0-py3-none-any.whl (483 kB)\n",
      "Downloading transformers-4.55.2-py3-none-any.whl (11.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m38.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached huggingface_hub-0.34.4-py3-none-any.whl (561 kB)\n",
      "Using cached hf_xet-1.1.7-cp37-abi3-macosx_11_0_arm64.whl (2.6 MB)\n",
      "Using cached tokenizers-0.21.4-cp39-abi3-macosx_11_0_arm64.whl (2.7 MB)\n",
      "Downloading scikit_learn-1.7.1-cp310-cp310-macosx_12_0_arm64.whl (8.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m36.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pypdf-6.0.0-py3-none-any.whl (310 kB)\n",
      "Using cached python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
      "Downloading openai-1.99.9-py3-none-any.whl (786 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m786.8/786.8 kB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading anyio-4.10.0-py3-none-any.whl (107 kB)\n",
      "Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Using cached httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Using cached httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "Downloading jiter-0.10.0-cp310-cp310-macosx_11_0_arm64.whl (322 kB)\n",
      "Downloading tiktoken-0.11.0-cp310-cp310-macosx_11_0_arm64.whl (999 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m999.2/999.2 kB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached fastapi-0.116.1-py3-none-any.whl (95 kB)\n",
      "Downloading starlette-0.47.2-py3-none-any.whl (72 kB)\n",
      "Using cached uvicorn-0.35.0-py3-none-any.whl (66 kB)\n",
      "Downloading supabase-2.18.1-py3-none-any.whl (18 kB)\n",
      "Downloading postgrest-1.1.1-py3-none-any.whl (22 kB)\n",
      "Downloading realtime-2.7.0-py3-none-any.whl (22 kB)\n",
      "Downloading storage3-0.12.1-py3-none-any.whl (18 kB)\n",
      "Downloading supabase_auth-2.12.3-py3-none-any.whl (44 kB)\n",
      "Downloading supabase_functions-0.10.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading deprecation-2.1.0-py2.py3-none-any.whl (11 kB)\n",
      "Downloading h2-4.2.0-py3-none-any.whl (60 kB)\n",
      "Downloading hpack-4.1.0-py3-none-any.whl (34 kB)\n",
      "Downloading hyperframe-6.1.0-py3-none-any.whl (13 kB)\n",
      "Downloading PyJWT-2.10.1-py3-none-any.whl (22 kB)\n",
      "Downloading StrEnum-0.4.15-py3-none-any.whl (8.9 kB)\n",
      "Downloading websockets-15.0.1-cp310-cp310-macosx_11_0_arm64.whl (173 kB)\n",
      "Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Using cached aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached attrs-25.3.0-py3-none-any.whl (63 kB)\n",
      "Using cached backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Using cached bcrypt-4.3.0-cp39-abi3-macosx_10_12_universal2.whl (498 kB)\n",
      "Downloading build-1.3.0-py3-none-any.whl (23 kB)\n",
      "Using cached certifi-2025.8.3-py3-none-any.whl (161 kB)\n",
      "Using cached click-8.2.1-py3-none-any.whl (102 kB)\n",
      "Using cached frozenlist-1.7.0-cp310-cp310-macosx_11_0_arm64.whl (46 kB)\n",
      "Using cached fsspec-2025.7.0-py3-none-any.whl (199 kB)\n",
      "Downloading grpcio-1.74.0-cp310-cp310-macosx_11_0_universal2.whl (11.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.0/11.0 MB\u001b[0m \u001b[31m39.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Using cached joblib-1.5.1-py3-none-any.whl (307 kB)\n",
      "Using cached jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Using cached jsonschema-4.25.0-py3-none-any.whl (89 kB)\n",
      "Using cached jsonschema_specifications-2025.4.1-py3-none-any.whl (18 kB)\n",
      "Using cached kubernetes-33.1.0-py2.py3-none-any.whl (1.9 MB)\n",
      "Using cached durationpy-0.10-py3-none-any.whl (3.9 kB)\n",
      "Using cached google_auth-2.40.3-py2.py3-none-any.whl (216 kB)\n",
      "Using cached cachetools-5.5.2-py3-none-any.whl (10 kB)\n",
      "Using cached rsa-4.9.1-py3-none-any.whl (34 kB)\n",
      "Downloading langsmith-0.4.14-py3-none-any.whl (373 kB)\n",
      "Downloading mmh3-5.2.0-cp310-cp310-macosx_11_0_arm64.whl (40 kB)\n",
      "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
      "Using cached numpy-2.2.6-cp310-cp310-macosx_14_0_arm64.whl (5.3 MB)\n",
      "Using cached oauthlib-3.3.1-py3-none-any.whl (160 kB)\n",
      "Downloading onnxruntime-1.22.1-cp310-cp310-macosx_13_0_universal2.whl (34.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.3/34.3 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading opentelemetry_api-1.36.0-py3-none-any.whl (65 kB)\n",
      "Using cached importlib_metadata-8.7.0-py3-none-any.whl (27 kB)\n",
      "Downloading opentelemetry_exporter_otlp_proto_grpc-1.36.0-py3-none-any.whl (18 kB)\n",
      "Downloading opentelemetry_exporter_otlp_proto_common-1.36.0-py3-none-any.whl (18 kB)\n",
      "Downloading opentelemetry_proto-1.36.0-py3-none-any.whl (72 kB)\n",
      "Using cached googleapis_common_protos-1.70.0-py3-none-any.whl (294 kB)\n",
      "Downloading opentelemetry_sdk-1.36.0-py3-none-any.whl (119 kB)\n",
      "Downloading opentelemetry_semantic_conventions-0.57b0-py3-none-any.whl (201 kB)\n",
      "Downloading protobuf-6.32.0-cp39-abi3-macosx_10_9_universal2.whl (426 kB)\n",
      "Downloading orjson-3.11.2-cp310-cp310-macosx_10_15_x86_64.macosx_11_0_arm64.macosx_10_15_universal2.whl (226 kB)\n",
      "Using cached overrides-7.7.0-py3-none-any.whl (17 kB)\n",
      "Using cached propcache-0.3.2-cp310-cp310-macosx_11_0_arm64.whl (43 kB)\n",
      "Using cached pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
      "Using cached pyasn1_modules-0.4.2-py3-none-any.whl (181 kB)\n",
      "Downloading pybase64-1.4.2-cp310-cp310-macosx_11_0_arm64.whl (31 kB)\n",
      "Using cached PyYAML-6.0.2-cp310-cp310-macosx_11_0_arm64.whl (171 kB)\n",
      "Using cached referencing-0.36.2-py3-none-any.whl (26 kB)\n",
      "Downloading regex-2025.7.34-cp310-cp310-macosx_11_0_arm64.whl (285 kB)\n",
      "Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Downloading rich-14.1.0-py3-none-any.whl (243 kB)\n",
      "Downloading markdown_it_py-4.0.0-py3-none-any.whl (87 kB)\n",
      "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Downloading rpds_py-0.27.0-cp310-cp310-macosx_11_0_arm64.whl (354 kB)\n",
      "Using cached safetensors-0.6.2-cp38-abi3-macosx_11_0_arm64.whl (432 kB)\n",
      "Using cached scipy-1.15.3-cp310-cp310-macosx_14_0_arm64.whl (22.4 MB)\n",
      "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Using cached threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Downloading tomli-2.2.1-py3-none-any.whl (14 kB)\n",
      "Downloading torch-2.8.0-cp310-none-macosx_11_0_arm64.whl (73.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.6/73.6 MB\u001b[0m \u001b[31m31.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Using cached typer-0.16.0-py3-none-any.whl (46 kB)\n",
      "Using cached shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Using cached typing_inspection-0.4.1-py3-none-any.whl (14 kB)\n",
      "Downloading httptools-0.6.4-cp310-cp310-macosx_11_0_arm64.whl (103 kB)\n",
      "Downloading uvloop-0.21.0-cp310-cp310-macosx_10_9_universal2.whl (1.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading watchfiles-1.1.0-cp310-cp310-macosx_11_0_arm64.whl (397 kB)\n",
      "Using cached websocket_client-1.8.0-py3-none-any.whl (58 kB)\n",
      "Using cached zipp-3.23.0-py3-none-any.whl (10 kB)\n",
      "Downloading zstandard-0.24.0-cp310-cp310-macosx_11_0_arm64.whl (640 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m640.5/640.5 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "Using cached humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "Downloading filelock-3.19.1-py3-none-any.whl (15 kB)\n",
      "Using cached flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
      "Using cached importlib_resources-6.5.2-py3-none-any.whl (37 kB)\n",
      "Using cached jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Using cached MarkupSafe-3.0.2-cp310-cp310-macosx_11_0_arm64.whl (12 kB)\n",
      "Using cached networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "Using cached pillow-11.3.0-cp310-cp310-macosx_11_0_arm64.whl (4.7 MB)\n",
      "Using cached pyproject_hooks-1.2.0-py3-none-any.whl (10 kB)\n",
      "Using cached requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Building wheels for collected packages: pypika\n",
      "  Building wheel for pypika (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pypika: filename=pypika-0.48.9-py2.py3-none-any.whl size=53803 sha256=6aaa771d2e2c997b911019d91a3793b7a1ea839b68e02444c23d0f2432132e97\n",
      "  Stored in directory: /Users/saniyaacharya/Library/Caches/pip/wheels/e1/26/51/d0bffb3d2fd82256676d7ad3003faea3bd6dddc9577af665f4\n",
      "Successfully built pypika\n",
      "Installing collected packages: strenum, pypika, mpmath, flatbuffers, durationpy, zstandard, zipp, websockets, websocket-client, uvloop, urllib3, typing-inspection, tqdm, tomli, threadpoolctl, tenacity, sympy, SQLAlchemy, sniffio, shellingham, safetensors, rpds-py, regex, PyYAML, python-dotenv, pyproject_hooks, pypdf, pyjwt, pydantic-core, pybase64, pyasn1, protobuf, propcache, Pillow, overrides, orjson, oauthlib, numpy, networkx, mypy-extensions, multidict, mmh3, mdurl, marshmallow, MarkupSafe, jsonpointer, joblib, jiter, importlib-resources, idna, hyperframe, humanfriendly, httpx-sse, httptools, hpack, hf-xet, h11, grpcio, fsspec, frozenlist, filelock, distro, deprecation, click, charset_normalizer, certifi, cachetools, bcrypt, backoff, attrs, async-timeout, annotated-types, aiohappyeyeballs, yarl, uvicorn, typing-inspect, scipy, rsa, requests, referencing, pydantic, pyasn1-modules, opentelemetry-proto, markdown-it-py, jsonpatch, jinja2, importlib-metadata, httpcore, h2, googleapis-common-protos, coloredlogs, build, anyio, aiosignal, watchfiles, torch, tiktoken, starlette, scikit-learn, rich, requests-toolbelt, requests-oauthlib, realtime, pydantic-settings, posthog, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, onnxruntime, jsonschema-specifications, huggingface-hub, httpx, google-auth, dataclasses-json, aiohttp, typer, tokenizers, opentelemetry-semantic-conventions, openai, langsmith, kubernetes, jsonschema, fastapi, transformers, supabase-functions, supabase-auth, storage3, postgrest, opentelemetry-sdk, langchain-core, supabase, sentence-transformers, opentelemetry-exporter-otlp-proto-grpc, langchain-text-splitters, langchain, chromadb, langchain-community\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m136/136\u001b[0m [langchain-community]ommunity]ansformers]os]\n",
      "\u001b[1A\u001b[2KSuccessfully installed MarkupSafe-3.0.2 Pillow-11.3.0 PyYAML-6.0.2 SQLAlchemy-2.0.43 aiohappyeyeballs-2.6.1 aiohttp-3.12.15 aiosignal-1.4.0 annotated-types-0.7.0 anyio-4.10.0 async-timeout-4.0.3 attrs-25.3.0 backoff-2.2.1 bcrypt-4.3.0 build-1.3.0 cachetools-5.5.2 certifi-2025.8.3 charset_normalizer-3.4.3 chromadb-1.0.17 click-8.2.1 coloredlogs-15.0.1 dataclasses-json-0.6.7 deprecation-2.1.0 distro-1.9.0 durationpy-0.10 fastapi-0.116.1 filelock-3.19.1 flatbuffers-25.2.10 frozenlist-1.7.0 fsspec-2025.7.0 google-auth-2.40.3 googleapis-common-protos-1.70.0 grpcio-1.74.0 h11-0.16.0 h2-4.2.0 hf-xet-1.1.7 hpack-4.1.0 httpcore-1.0.9 httptools-0.6.4 httpx-0.28.1 httpx-sse-0.4.1 huggingface-hub-0.34.4 humanfriendly-10.0 hyperframe-6.1.0 idna-3.10 importlib-metadata-8.7.0 importlib-resources-6.5.2 jinja2-3.1.6 jiter-0.10.0 joblib-1.5.1 jsonpatch-1.33 jsonpointer-3.0.0 jsonschema-4.25.0 jsonschema-specifications-2025.4.1 kubernetes-33.1.0 langchain-0.3.27 langchain-community-0.3.27 langchain-core-0.3.74 langchain-text-splitters-0.3.9 langsmith-0.4.14 markdown-it-py-4.0.0 marshmallow-3.26.1 mdurl-0.1.2 mmh3-5.2.0 mpmath-1.3.0 multidict-6.6.4 mypy-extensions-1.1.0 networkx-3.4.2 numpy-2.2.6 oauthlib-3.3.1 onnxruntime-1.22.1 openai-1.99.9 opentelemetry-api-1.36.0 opentelemetry-exporter-otlp-proto-common-1.36.0 opentelemetry-exporter-otlp-proto-grpc-1.36.0 opentelemetry-proto-1.36.0 opentelemetry-sdk-1.36.0 opentelemetry-semantic-conventions-0.57b0 orjson-3.11.2 overrides-7.7.0 postgrest-1.1.1 posthog-5.4.0 propcache-0.3.2 protobuf-6.32.0 pyasn1-0.6.1 pyasn1-modules-0.4.2 pybase64-1.4.2 pydantic-2.11.7 pydantic-core-2.33.2 pydantic-settings-2.10.1 pyjwt-2.10.1 pypdf-6.0.0 pypika-0.48.9 pyproject_hooks-1.2.0 python-dotenv-1.1.1 realtime-2.7.0 referencing-0.36.2 regex-2025.7.34 requests-2.32.4 requests-oauthlib-2.0.0 requests-toolbelt-1.0.0 rich-14.1.0 rpds-py-0.27.0 rsa-4.9.1 safetensors-0.6.2 scikit-learn-1.7.1 scipy-1.15.3 sentence-transformers-5.1.0 shellingham-1.5.4 sniffio-1.3.1 starlette-0.47.2 storage3-0.12.1 strenum-0.4.15 supabase-2.18.1 supabase-auth-2.12.3 supabase-functions-0.10.1 sympy-1.14.0 tenacity-9.1.2 threadpoolctl-3.6.0 tiktoken-0.11.0 tokenizers-0.21.4 tomli-2.2.1 torch-2.8.0 tqdm-4.67.1 transformers-4.55.2 typer-0.16.0 typing-inspect-0.9.0 typing-inspection-0.4.1 urllib3-2.5.0 uvicorn-0.35.0 uvloop-0.21.0 watchfiles-1.1.0 websocket-client-1.8.0 websockets-15.0.1 yarl-1.20.1 zipp-3.23.0 zstandard-0.24.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/opt/homebrew/opt/python@3.10/bin/python3.10 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# If running locally/Colab: install dependencies\n",
    "%pip install -U langchain langchain-community chromadb sentence-transformers scikit-learn pypdf python-dotenv openai tiktoken fastapi uvicorn pydantic supabase\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "811ab311",
   "metadata": {},
   "source": [
    "Imports & Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c12fc35c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI enabled: False\n"
     ]
    }
   ],
   "source": [
    "import os, uuid, textwrap\n",
    "from pathlib import Path\n",
    "from typing import List, Dict\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# LangChain community loaders & vector store\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "# Embeddings\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# ML (risk classifier)\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Optional LLM (OpenAI)\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\", \"\")\n",
    "HAS_OPENAI = bool(OPENAI_API_KEY)\n",
    "\n",
    "if HAS_OPENAI:\n",
    "    try:\n",
    "        from openai import OpenAI\n",
    "        openai_client = OpenAI()\n",
    "    except Exception as e:\n",
    "        print(\"OpenAI client not available:\", e)\n",
    "        HAS_OPENAI = False\n",
    "\n",
    "DATA_DIR = Path(\"docs\")\n",
    "DB_DIR = Path(\"chroma_db\")\n",
    "DATA_DIR.mkdir(exist_ok=True)\n",
    "DB_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "print(\"OpenAI enabled:\", HAS_OPENAI)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3622094b",
   "metadata": {},
   "source": [
    "Sample Docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be5f02f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created sample doc: docs/sample_compliance.txt\n"
     ]
    }
   ],
   "source": [
    "SAMPLE_TXT = \"\"\"\n",
    "AML Policy (Sample):\n",
    "Cash deposits equal to or above $10,000 require enhanced due diligence (EDD).\n",
    "EDD includes source-of-funds verification and a customer declaration.\n",
    "Suspicious activity must be reported per SAR procedures.\n",
    "\n",
    "GDPR (Sample):\n",
    "Personal data must be processed lawfully, fairly, and transparently (Article 5).\n",
    "Special categories of personal data require explicit consent unless another legal basis applies (Article 9).\n",
    "Data subjects have the right to access and rectify their data.\n",
    "\"\"\"\n",
    "\n",
    "sample_path = DATA_DIR / \"sample_compliance.txt\"\n",
    "if not sample_path.exists():\n",
    "    sample_path.write_text(SAMPLE_TXT)\n",
    "    print(\"Created sample doc:\", sample_path)\n",
    "else:\n",
    "    print(\"Sample already exists:\", sample_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d101d0af",
   "metadata": {},
   "source": [
    "Ingest & Chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "303206f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded documents: 1\n",
      "Total chunks: 1\n",
      "Example chunk: AML Policy (Sample): Cash deposits equal to or above $10,000 require enhanced due diligence (EDD). EDD includes source-of-funds verification and a customer declaration. Suspicious activity must be reported per SAR procedures. GDPR (Sample): [...]\n"
     ]
    }
   ],
   "source": [
    "def load_docs(data_dir: Path) -> List[Dict]:\n",
    "    docs = []\n",
    "    # TXT\n",
    "    for p in data_dir.glob(\"*.txt\"):\n",
    "        docs.append({\"source\": str(p), \"text\": Path(p).read_text(errors=\"ignore\")})\n",
    "    # PDF\n",
    "    for p in data_dir.glob(\"*.pdf\"):\n",
    "        try:\n",
    "            pages = PyPDFLoader(str(p)).load()\n",
    "            combined = \"\\n\".join(pg.page_content for pg in pages)\n",
    "            docs.append({\"source\": str(p), \"text\": combined})\n",
    "        except Exception as e:\n",
    "            print(\"PDF load failed:\", p, e)\n",
    "    return docs\n",
    "\n",
    "docs = load_docs(DATA_DIR)\n",
    "print(\"Loaded documents:\", len(docs))\n",
    "assert docs, \"No documents found. Put PDFs/TXT in docs/ and re-run.\"\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=800, chunk_overlap=100)\n",
    "chunks = []\n",
    "for d in docs:\n",
    "    for ch in splitter.split_text(d[\"text\"]):\n",
    "        chunks.append({\"source\": d[\"source\"], \"text\": ch})\n",
    "\n",
    "print(\"Total chunks:\", len(chunks))\n",
    "print(\"Example chunk:\", textwrap.shorten(chunks[0][\"text\"], 250))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0380b253",
   "metadata": {},
   "source": [
    "Embeddings & Vector Store (Chroma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f99e0b26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0h/scqyrwfn4mj3fpkcf941nz9r0000gn/T/ipykernel_10728/449158471.py:4: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embedding_function = SentenceTransformerEmbeddings(model=embed_model)\n"
     ]
    },
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for HuggingFaceEmbeddings\nmodel\n  Extra inputs are not permitted [type=extra_forbidden, input_value=SentenceTransformer(\n  (0...e})\n  (2): Normalize()\n), input_type=SentenceTransformer]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain_community\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01membeddings\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SentenceTransformerEmbeddings\n\u001b[1;32m      3\u001b[0m embed_model \u001b[38;5;241m=\u001b[39m SentenceTransformer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall-MiniLM-L6-v2\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m embedding_function \u001b[38;5;241m=\u001b[39m \u001b[43mSentenceTransformerEmbeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membed_model\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m texts \u001b[38;5;241m=\u001b[39m [c[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m chunks]\n\u001b[1;32m      7\u001b[0m metadatas \u001b[38;5;241m=\u001b[39m [{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: c[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m]} \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m chunks]\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:223\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.finalize.<locals>.warn_if_direct_instance\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    221\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    222\u001b[0m     emit_warning()\n\u001b[0;32m--> 223\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/langchain_community/embeddings/huggingface.py:69\u001b[0m, in \u001b[0;36mHuggingFaceEmbeddings.__init__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any):\n\u001b[1;32m     68\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Initialize the sentence_transformer.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 69\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_name\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m kwargs:\n\u001b[1;32m     72\u001b[0m         since \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0.2.16\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/pydantic/main.py:253\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[0;34m(self, **data)\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;66;03m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[39;00m\n\u001b[1;32m    252\u001b[0m __tracebackhide__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 253\u001b[0m validated_self \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mself_instance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m validated_self:\n\u001b[1;32m    255\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    256\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA custom validator is returning a value other than `self`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    257\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReturning anything other than `self` from a top level model validator isn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt supported when validating via `__init__`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSee the `model_validator` docs (https://docs.pydantic.dev/latest/concepts/validators/#model-validators) for more details.\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    259\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m    260\u001b[0m     )\n",
      "\u001b[0;31mValidationError\u001b[0m: 1 validation error for HuggingFaceEmbeddings\nmodel\n  Extra inputs are not permitted [type=extra_forbidden, input_value=SentenceTransformer(\n  (0...e})\n  (2): Normalize()\n), input_type=SentenceTransformer]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden"
     ]
    }
   ],
   "source": [
    "from langchain_community.embeddings import SentenceTransformerEmbeddings\n",
    "\n",
    "embed_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "embedding_function = SentenceTransformerEmbeddings(model=embed_model)\n",
    "\n",
    "texts = [c[\"text\"] for c in chunks]\n",
    "metadatas = [{\"source\": c[\"source\"]} for c in chunks]\n",
    "\n",
    "import shutil\n",
    "if DB_DIR.exists():\n",
    "    shutil.rmtree(DB_DIR)\n",
    "vectorstore = Chroma(\n",
    "    collection_name=\"compliance_demo\",\n",
    "    embedding_function=embedding_function,\n",
    "    persist_directory=str(DB_DIR),\n",
    ")\n",
    "\n",
    "# Clear old & add\n",
    "all_ids = vectorstore._collection.get()['ids']\n",
    "if all_ids:\n",
    "    vectorstore._collection.delete(ids=all_ids)\n",
    "vectorstore.add_texts(texts=texts, metadatas=metadatas)\n",
    "vectorstore.persist()\n",
    "\n",
    "print(\"Chroma collection size:\", vectorstore._collection.count())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724dc1a2",
   "metadata": {},
   "source": [
    "Retrieval test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1fc3692",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve(query: str, k: int = 4):\n",
    "    results = vectorstore.similarity_search(query, k=k)\n",
    "    return [{\"text\": r.page_content, \"source\": r.metadata.get(\"source\", \"unknown\")} for r in results]\n",
    "\n",
    "query = \"Cash deposit $12,000 — what steps per AML?\"\n",
    "hits = retrieve(query)\n",
    "for i, h in enumerate(hits, 1):\n",
    "    print(f\"[{i}] source={h['source']}\\n{textwrap.shorten(h['text'], 300)}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ba055c",
   "metadata": {},
   "source": [
    "Answer generation (with citations)\n",
    "\n",
    "Uses OpenAI if OPENAI_API_KEY is set.\n",
    "\n",
    "Otherwise, returns a concise, extractive fallback using the retrieved chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38cc9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_answer(question: str, context_chunks: List[Dict]):\n",
    "    citations = [c[\"source\"] for c in context_chunks]\n",
    "    context_text = \"\\n\\n\".join(c[\"text\"] for c in context_chunks)\n",
    "\n",
    "    if HAS_OPENAI:\n",
    "        prompt = f\"\"\"\n",
    "You are a warm, accurate Risk & Compliance Advisor AI.\n",
    "Use only the context to answer. If unsure, say what's missing and suggest next steps.\n",
    "Cite the file names used.\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Context:\n",
    "{context_text}\n",
    "\n",
    "Respond briefly, with citations.\n",
    "\"\"\"\n",
    "        try:\n",
    "            resp = openai_client.chat.completions.create(\n",
    "                model=\"gpt-4o-mini\",\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "                temperature=0.2,\n",
    "            )\n",
    "            answer = resp.choices[0].message.content\n",
    "        except Exception as e:\n",
    "            answer = f\"(LLM unavailable: {e})\\n\\nKey context:\\n{textwrap.shorten(context_text, 500)}\\n\\nCitations: {sorted(set(citations))}\"\n",
    "    else:\n",
    "        # simple extractive fallback\n",
    "        answer = (\n",
    "            \"Based on the retrieved policy text, cash deposits at or above $10,000 require \"\n",
    "            \"enhanced due diligence (e.g., source-of-funds and declaration). For $12,000, take EDD \"\n",
    "            \"steps and follow SAR procedures if any red flags arise. Citations: \"\n",
    "            + \", \".join(sorted(set(citations)))\n",
    "        )\n",
    "    return answer, sorted(set(citations))\n",
    "\n",
    "ans, cites = generate_answer(query, hits)\n",
    "print(ans, \"\\n\\nCitations:\", cites)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9193d064",
   "metadata": {},
   "source": [
    "Train a simple Risk Classifier (red flags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0841e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [\n",
    "    (\"Customer deposits $12,000 cash with unclear source of funds\", 1),\n",
    "    (\"Multiple small cash deposits under $9,900 in a week\", 1),\n",
    "    (\"Transfer to high-risk jurisdiction without documentation\", 1),\n",
    "    (\"Politically exposed person requests expedited onboarding\", 1),\n",
    "    (\"Monthly salary credited via bank transfer\", 0),\n",
    "    (\"Customer updates address details\", 0),\n",
    "    (\"Fixed deposit renewal with KYC completed\", 0),\n",
    "    (\"Tax payment to government account\", 0),\n",
    "]\n",
    "texts = [t for t, y in examples]\n",
    "labels = [y for t, y in examples]\n",
    "\n",
    "tfidf = TfidfVectorizer(ngram_range=(1,2), max_features=3000)\n",
    "X = tfidf.fit_transform(texts)\n",
    "Xtr, Xte, ytr, yte = train_test_split(X, labels, test_size=0.25, random_state=42, stratify=labels)\n",
    "\n",
    "clf = LogisticRegression(max_iter=1000)\n",
    "clf.fit(Xtr, ytr)\n",
    "pred = clf.predict(Xte)\n",
    "print(classification_report(yte, pred, digits=3))\n",
    "\n",
    "def score_risk(text: str):\n",
    "    p = clf.predict_proba(tfidf.transform([text]))[0][1]\n",
    "    level = \"Low\"\n",
    "    if p >= 0.75:\n",
    "        level = \"High\"\n",
    "    elif p >= 0.40:\n",
    "        level = \"Medium\"\n",
    "    return {\"probability\": float(p), \"level\": level}\n",
    "\n",
    "print(\"Risk demo:\", score_risk(\"Client deposits $12,000 cash with unclear source of funds\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021c1ea0",
   "metadata": {},
   "source": [
    "End-to-end ask() (answer + citations + risk + context preview)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb41357",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask(question: str, k: int = 4):\n",
    "    ctx = retrieve(question, k=k)\n",
    "    answer, citations = generate_answer(question, ctx)\n",
    "    risk = score_risk(question)\n",
    "    return {\n",
    "        \"question\": question,\n",
    "        \"answer\": answer,\n",
    "        \"citations\": citations,\n",
    "        \"risk\": risk,\n",
    "        \"context_preview\": [textwrap.shorten(c[\"text\"], 220) for c in ctx],\n",
    "    }\n",
    "\n",
    "demo = ask(\"Client from Country X wants to deposit $12,000 in cash. Do I need extra steps?\")\n",
    "demo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105e2eb8",
   "metadata": {},
   "source": [
    "Minimal FastAPI backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f595ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile main.py\n",
    "from fastapi import FastAPI\n",
    "from pydantic import BaseModel\n",
    "from typing import List\n",
    "\n",
    "# --- import the notebook functions by copying them above this file or placing them in a module ---\n",
    "# For quick demo, you can paste retrieve/generate_answer/score_risk/ask here.\n",
    "\n",
    "app = FastAPI(title=\"Compliance Advisor API\", version=\"1.0\")\n",
    "\n",
    "class AskBody(BaseModel):\n",
    "    question: str\n",
    "    k: int = 4\n",
    "\n",
    "@app.get(\"/health\")\n",
    "def health():\n",
    "    return {\"ok\": True}\n",
    "\n",
    "@app.post(\"/ask\")\n",
    "def api_ask(body: AskBody):\n",
    "    # call the ask() you defined above\n",
    "    from __main__ import ask  # NOTE: in production, import from a module\n",
    "    return ask(body.question, k=body.k)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77255c9a",
   "metadata": {},
   "source": [
    "Supabase: push doc metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d9e134",
   "metadata": {},
   "outputs": [],
   "source": [
    "SUPABASE_URL = os.getenv(\"SUPABASE_URL\")\n",
    "SUPABASE_KEY = os.getenv(\"SUPABASE_SERVICE_ROLE_KEY\") or os.getenv(\"SUPABASE_ANON_KEY\")\n",
    "HAS_SB = bool(SUPABASE_URL and SUPABASE_KEY)\n",
    "print(\"Supabase configured:\", HAS_SB)\n",
    "\n",
    "if HAS_SB:\n",
    "    try:\n",
    "        from supabase import create_client\n",
    "        sb = create_client(SUPABASE_URL, SUPABASE_KEY)\n",
    "        rows = [{\"id\": str(uuid.uuid4()), \"path\": c[\"source\"]} for c in chunks[:5]]\n",
    "        res = sb.table(\"documents\").insert(rows).execute()\n",
    "        print(\"Inserted sample rows into Supabase.documents\")\n",
    "    except Exception as e:\n",
    "        print(\"Supabase error:\", e)\n",
    "else:\n",
    "    print(\"Set SUPABASE_URL and SUPABASE_SERVICE_ROLE_KEY/ANON_KEY to enable.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
